{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284ba83d-b0dc-4f6e-b49c-56b9d6c0de6b",
   "metadata": {},
   "source": [
    "### Step 1: Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5aaaf25-374f-4be2-a85d-e53fa85d35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b34c6-5f85-46b4-b443-b3ea3fcfb4b6",
   "metadata": {},
   "source": [
    "### Step 2: Creation of Questions dataframe\n",
    "Currently there are 5 different files belonging to 5 different domain of the questions and in this module we will be creating a dataframe that will be having total of 1600 questions belonging to 5 different domains. The domains are \n",
    "- DSA questions\n",
    "- System design questions\n",
    "- AI questions\n",
    "- Computer fundamental questions\n",
    "- Behavioural questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b2b174c-9b54-48d2-a322-a6e6d64f741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['../Dataset/DSA_que.txt', '../Dataset/System_Design_que.txt', '../Dataset/Behavioural_que.txt',\n",
    "              '../Dataset/CS_fundamentals.txt', '../Dataset/AI_que.txt']\n",
    "que_type = {0: 'DSA',\n",
    "            1: 'System_design',\n",
    "            2: 'Behavioural',\n",
    "            3: 'CS_fundamentals',\n",
    "            4: 'AI'}\n",
    "count = 0\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Going over all the paths\n",
    "for paths in file_paths:\n",
    "    try:\n",
    "        # Reset que_ls for each file iteration\n",
    "        que_ls = []\n",
    "\n",
    "        with open(paths, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                # Removing the leading and following white space after reading content from the file\n",
    "                line = line.strip()\n",
    "                # Saving the line in the que list\n",
    "                que_ls.append(line)\n",
    "\n",
    "            # Creating series from the \n",
    "            que_sr = pd.Series(que_ls)\n",
    "            temp_df = pd.DataFrame({'Que': que_sr})\n",
    "\n",
    "            # Adding a feature 'Category'\n",
    "            temp_df['Category'] = que_type[count]\n",
    "            count = count + 1\n",
    "\n",
    "            # Concatenating the dataframes\n",
    "            df = pd.concat([df, temp_df], axis=0)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {paths} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f9c8ec8-6002-4c67-98f9-9e1a38afcc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the dataframe\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Resetting the index\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b9308f7-8ff0-4922-9699-cb41c0e2f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataframe\n",
    "df.to_csv('../Dataset/Que_Classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616870a-232e-4d5c-9efa-f1e38a3ecd23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
